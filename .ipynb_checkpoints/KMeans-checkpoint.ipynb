{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-2eae7f1c06ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"splitedKeyword.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mdocuments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-/:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "#df = pd.read_csv('splitKeyword.txt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "#documents = df.values.tolist()\n",
    "fo = open(\"splitedKeyword.txt\", \"r\")\n",
    "documents = fo.readlines()\n",
    "print(documents)\n",
    "\n",
    "#documents = [\"This little kitty came to play when I was eating at a restaurant.\",\n",
    " #            \"Merley has the best squooshy kitten belly.\",\n",
    "  #          \"If you open 100 tab in google you get a smiley face.\",\n",
    "   #          \"Best cat photo I've ever taken.\",\n",
    "    #         \"Climbing ninja cat.\",\n",
    "     #        \"Impressed with google map feedback.\",\n",
    "      #       \"Key promoter extension for Google Chrome.\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "Y = vectorizer.transform([\"chrome browser to open.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"My cat is hungry.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SchemeURLLinking Root DomainsExternal LinksmozRankmozTrust\n",
      "0                            /1426252737373247969.89.5        \n",
      "1                           /972949153428348509.649.44        \n",
      "2                           /808090522623820949.529.35        \n",
      "3                            /525875514323927949.359.2        \n",
      "4                           /377058713486011609.259.01        \n",
      "5                             /35510397490488899.29.06        \n",
      "6                            /34841702626301689.168.79        \n",
      "7                             /22617036668445408.98.69        \n",
      "8                             /19284741927245078.88.66        \n",
      "9                            /15163362146208778.698.64        \n",
      "10                           /14173716166902708.538.45        \n",
      "11                           /12371112457791479.159.08        \n",
      "12                            /1159943672857688.959.06        \n",
      "13                           /10740467197937868.538.37        \n",
      "14                             /1041599663387368.638.6        \n",
      "15                           /10087661944612548.578.57        \n",
      "16                             /9952991533668758.78.51        \n",
      "17                             /913255670157878.618.53        \n",
      "18                            /7798122543046078.458.54        \n",
      "19                             /765478845458588.898.72        \n",
      "20                             /744525912710118.398.39        \n",
      "21                              /72924195372878.568.03        \n",
      "22                            /7023952336705118.477.56        \n",
      "23                            /6586481136578308.528.49        \n",
      "24                            /5859601461508558.267.73        \n",
      "25                             /534343895193758.077.99        \n",
      "26                            /4362021784584228.348.79        \n",
      "27                             /4361872361999678.37.42        \n",
      "28                             /426032308559448.188.85        \n",
      "29                            /4199866901374578.288.27        \n",
      "..                                                 ...        \n",
      "470                               /325136788857.447.63        \n",
      "471                             /32435185260777.368.77        \n",
      "472                              /3224813202237.318.01        \n",
      "473                              /3216628390867.367.39        \n",
      "474                              /3212735259197.347.13        \n",
      "475                               /321079224177.457.72        \n",
      "476                               /3207820621377.536.9        \n",
      "477                               /318928425347.318.75        \n",
      "478                              /3141023030247.338.74        \n",
      "479                              /3139522826607.427.51        \n",
      "480                               /313323620777.316.68        \n",
      "481                               /312485334077.317.21        \n",
      "482                               /3112416252858.217.8        \n",
      "483                              /3094332688107.428.76        \n",
      "484                               /3071215663447.87.77        \n",
      "485                               /3062114270597.47.18        \n",
      "486                             /30435111797557.368.46        \n",
      "487                              /3040435337617.347.53        \n",
      "488                              /3015223042137.327.32        \n",
      "489                               /299754179677.697.54        \n",
      "490                              /2966868619677.437.16        \n",
      "491                               /2937134989677.46.82        \n",
      "492                               /2917022615697.67.15        \n",
      "493                               /291346628627.357.75        \n",
      "494                               /290554475717.367.55        \n",
      "495                             /28459238402367.427.58        \n",
      "496                              /2844127812177.887.64        \n",
      "497                               /2839322286257.48.74        \n",
      "498                               /282741220847.346.61        \n",
      "499                             /28266101931337.337.52        \n",
      "\n",
      "[500 rows x 1 columns]\n",
      "Schema:\n",
      "\n",
      " SchemeURLLinking Root DomainsExternal LinksmozRankmozTrust    object\n",
      "dtype: object\n",
      "Number of questions,columns= (500, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "# read json into a dataframe\n",
    "df_idf=pd.read_csv(\"keyword.txt\")\n",
    "#print(df_idf)\n",
    " \n",
    "# print schema\n",
    "print(\"Schema:\\n\\n\",df_idf.dtypes)\n",
    "print(\"Number of questions,columns=\",df_idf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'title'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3077\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3078\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-918bbfbaff5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf_idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf_idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'body'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mdf_idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_idf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpre_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2688\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2695\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2489\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   4113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4115\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'title'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def pre_process(text):\n",
    "    \n",
    "    # lowercase\n",
    "    text=text.lower()\n",
    "    \n",
    "    #remove tags\n",
    "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
    "    \n",
    "    # remove special characters and digits\n",
    "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
    "    \n",
    "    return text\n",
    " \n",
    "df_idf['text'] = df_idf['title'] + df_idf['body']\n",
    "df_idf['text'] = df_idf['text'].apply(lambda x:pre_process(x))\n",
    " \n",
    "#show the second 'text' just for fun\n",
    "df_idf['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents = [\"This little kitty came to play when I was eating at a restaurant.\",\n",
      "             \"Merley has the best squooshy kitten belly.\",\n",
      "             \"Google Translate app is incredible.\",\n",
      "             \"If you open 100 tab in google you get a smiley face.\",\n",
      "             \"Best cat photo I've ever taken.\",\n",
      "             \"Climbing ninja cat.\",\n",
      "             \"Impressed with google map feedback.\",\n",
      "             \"Key promoter extension for Google Chrome.\"]\n",
      "Usage: ipykernel_launcher.py [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --lsa=N_COMPONENTS    Preprocess documents with latent semantic analysis.\n",
      "  --no-minibatch        Use ordinary k-means algorithm (in batch mode).\n",
      "  --no-idf              Disable Inverse Document Frequency feature weighting.\n",
      "  --use-hashing         Use a hashing feature vectorizer\n",
      "  --n-features=N_FEATURES\n",
      "                        Maximum number of features (dimensions) to extract\n",
      "                        from text.\n",
      "  --verbose             Print progress reports inside k-means algorithm.\n",
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
      "3387 documents\n",
      "4 categories\n",
      "\n",
      "Extracting features from the training dataset using a sparse vectorizer\n",
      "done in 1.156165s\n",
      "n_samples: 3387, n_features: 10000\n",
      "\n",
      "Clustering sparse data with MiniBatchKMeans(batch_size=1000, compute_labels=True, init='k-means++',\n",
      "        init_size=1000, max_iter=100, max_no_improvement=10, n_clusters=4,\n",
      "        n_init=1, random_state=None, reassignment_ratio=0.01, tol=0.0,\n",
      "        verbose=False)\n",
      "done in 0.110s\n",
      "\n",
      "Homogeneity: 0.575\n",
      "Completeness: 0.607\n",
      "V-measure: 0.591\n",
      "Adjusted Rand-Index: 0.575\n",
      "Silhouette Coefficient: 0.008\n",
      "\n",
      "Top terms per cluster:\n",
      "Cluster 0: keith sgi livesey morality caltech objective moral wpd solntze jon\n",
      "Cluster 1: graphics university image thanks com posting files file host ac\n",
      "Cluster 2: god com sandvik jesus people article don bible kent christian\n",
      "Cluster 3: space nasa henry access digex toronto gov alaska pat shuttle\n"
     ]
    }
   ],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Lars Buitinck\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# parse commandline arguments\n",
    "op = OptionParser()\n",
    "op.add_option(\"--lsa\",\n",
    "              dest=\"n_components\", type=\"int\",\n",
    "              help=\"Preprocess documents with latent semantic analysis.\")\n",
    "op.add_option(\"--no-minibatch\",\n",
    "              action=\"store_false\", dest=\"minibatch\", default=True,\n",
    "              help=\"Use ordinary k-means algorithm (in batch mode).\")\n",
    "op.add_option(\"--no-idf\",\n",
    "              action=\"store_false\", dest=\"use_idf\", default=True,\n",
    "              help=\"Disable Inverse Document Frequency feature weighting.\")\n",
    "op.add_option(\"--use-hashing\",\n",
    "              action=\"store_true\", default=False,\n",
    "              help=\"Use a hashing feature vectorizer\")\n",
    "op.add_option(\"--n-features\", type=int, default=10000,\n",
    "              help=\"Maximum number of features (dimensions)\"\n",
    "                   \" to extract from text.\")\n",
    "op.add_option(\"--verbose\",\n",
    "              action=\"store_true\", dest=\"verbose\", default=False,\n",
    "              help=\"Print progress reports inside k-means algorithm.\")\n",
    "\n",
    "print(__doc__)\n",
    "op.print_help()\n",
    "\n",
    "\n",
    "def is_interactive():\n",
    "    return not hasattr(sys.modules['__main__'], '__file__')\n",
    "\n",
    "\n",
    "# work-around for Jupyter notebook and IPython console\n",
    "argv = [] if is_interactive() else sys.argv[1:]\n",
    "(opts, args) = op.parse_args(argv)\n",
    "if len(args) > 0:\n",
    "    op.error(\"this script takes no arguments.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Load some categories from the training set\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "# categories = None\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories,\n",
    "                             shuffle=True, random_state=42)\n",
    "\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))\n",
    "print()\n",
    "\n",
    "labels = dataset.target\n",
    "true_k = np.unique(labels).shape[0]\n",
    "\n",
    "print(\"Extracting features from the training dataset \"\n",
    "      \"using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "if opts.use_hashing:\n",
    "    if opts.use_idf:\n",
    "        # Perform an IDF normalization on the output of HashingVectorizer\n",
    "        hasher = HashingVectorizer(n_features=opts.n_features,\n",
    "                                   stop_words='english', alternate_sign=False,\n",
    "                                   norm=None, binary=False)\n",
    "        vectorizer = make_pipeline(hasher, TfidfTransformer())\n",
    "    else:\n",
    "        vectorizer = HashingVectorizer(n_features=opts.n_features,\n",
    "                                       stop_words='english',\n",
    "                                       alternate_sign=False, norm='l2',\n",
    "                                       binary=False)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, max_features=opts.n_features,\n",
    "                                 min_df=2, stop_words='english',\n",
    "                                 use_idf=opts.use_idf)\n",
    "X = vectorizer.fit_transform(dataset.data)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "print()\n",
    "\n",
    "if opts.n_components:\n",
    "    print(\"Performing dimensionality reduction using LSA\")\n",
    "    t0 = time()\n",
    "    # Vectorizer results are normalized, which makes KMeans behave as\n",
    "    # spherical k-means for better results. Since LSA/SVD results are\n",
    "    # not normalized, we have to redo the normalization.\n",
    "    svd = TruncatedSVD(opts.n_components)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "    X = lsa.fit_transform(X)\n",
    "\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    print(\"Explained variance of the SVD step: {}%\".format(\n",
    "        int(explained_variance * 100)))\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Do the actual clustering\n",
    "\n",
    "if opts.minibatch:\n",
    "    km = MiniBatchKMeans(n_clusters=true_k, init='k-means++', n_init=1,\n",
    "                         init_size=1000, batch_size=1000, verbose=opts.verbose)\n",
    "else:\n",
    "    km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1,\n",
    "                verbose=opts.verbose)\n",
    "\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "if not opts.use_hashing:\n",
    "    print(\"Top terms per cluster:\")\n",
    "\n",
    "    if opts.n_components:\n",
    "        original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "        order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "    else:\n",
    "        order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(true_k):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e1c5228e86a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mtrue_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \"\"\"\n\u001b[1;32m   1602\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1603\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1604\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1032\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0mvocabulary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m                 raise ValueError(\"empty vocabulary; perhaps the documents only\"\n\u001b[0m\u001b[1;32m    962\u001b[0m                                  \" contain stop words\")\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('splitKeyword.txt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "documents = df.values.tolist()\n",
    "print(documents)\n",
    "\n",
    "'''documents = [\"This little kitty came to play when I was eating at a restaurant.\",\n",
    "             \"Merley has the best squooshy kitten belly.\",\n",
    "             \"Google Translate app is incredible.\",\n",
    "             \"If you open 100 tab in google you get a smiley face.\",\n",
    "             \"Best cat photo I've ever taken.\",\n",
    "             \"Climbing ninja cat.\",\n",
    "             \"Impressed with google map feedback.\",\n",
    "             \"Key promoter extension for Google Chrome.\"]'''\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "Y = vectorizer.transform([\"chrome browser to open.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"My cat is hungry.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [teeth-whitening-treatments18'laser-teeth-whitening22'teeth-whitening-products21'200803breakthroughs-in-unwanted-hairremo'200803unwanted-hair-removal-products.html'200803unwanted-hair-removal-by-shaving.ht']\n",
      "Index: []\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "df = pd.read_csv('splitKeyword.csv')\n",
    "print (df)\n",
    "document = df.values.tolist()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SchemeURLLinking Root DomainsExternal LinksmozRankmozTrust\\n', '/1426252737373247969.89.5\\n', '/972949153428348509.649.44\\n', '/808090522623820949.529.35\\n', '/525875514323927949.359.2\\n', '/377058713486011609.259.01\\n', '/35510397490488899.29.06\\n', '/34841702626301689.168.79\\n', '/22617036668445408.98.69\\n', '/19284741927245078.88.66\\n', '/15163362146208778.698.64\\n', '/14173716166902708.538.45\\n', '/12371112457791479.159.08\\n', '/1159943672857688.959.06\\n', '/10740467197937868.538.37\\n', '/1041599663387368.638.6\\n', '/10087661944612548.578.57\\n', '/9952991533668758.78.51\\n', '/913255670157878.618.53\\n', '/7798122543046078.458.54\\n', '/765478845458588.898.72\\n', '/744525912710118.398.39\\n', '/72924195372878.568.03\\n', '/7023952336705118.477.56\\n', '/6586481136578308.528.49\\n', '/5859601461508558.267.73\\n', '/534343895193758.077.99\\n', '/4362021784584228.348.79\\n', '/4361872361999678.37.42\\n', '/426032308559448.188.85\\n', '/4199866901374578.288.27\\n', '/397517507438708.418.87\\n', '/3844414491528.547.62\\n', '/380613922272398.067.8\\n', '/378078762406818.318.05\\n', '/371954676172948.217.23\\n', '/363180103477027.867.45\\n', '/3578197219748317.97.69\\n', '/351349716522178.528.52\\n', '/344119104500188.068.05\\n', '/343712364946218.078.0\\n', '/339735218190788.288.81\\n', '/338281731250428.08.79\\n', '/3354251077353717.817.11\\n', '/332876361297837.757.69\\n', '/324899144233018.217.62\\n', '/2922161026063068.248.29\\n', '/287830998779088.048.85\\n', '/285986192673068.08.53\\n', '/284309224144748.327.72\\n', '/280409330119607.938.79\\n', '/278324613127707.687.63\\n', '/275213191556757.957.78\\n', '/273048571021577.667.68\\n', '/2692212816286797.997.86\\n', '/2681441080161238.168.85\\n', '/266495225296498.28.03\\n', '/264882105818717.97.8\\n', '/263877256036767.827.8\\n', '/263771256581357.928.07\\n', '/2603341467149797.97.89\\n', '/257576388137327.988.02\\n', '/24562582556107.737.66\\n', '/24465051047067.877.77\\n', '/23756469875328.058.06\\n', '/23598884732517.988.07\\n', '/235869629604508.237.53\\n', '/228378869986188.28.25\\n', '/22494298578808.097.91\\n', '/216037145855357.878.8\\n', '/215844212432787.357.11\\n', '/214652115570097.747.58\\n', '/208583200996867.868.78\\n', '/207220156316817.677.82\\n', '/206286125420247.98.11\\n', '/201720361271808.027.37\\n', '/197933163757207.928.05\\n', '/195799135561977.957.99\\n', '/1942575500387.827.01\\n', '/193343821101398.097.73\\n', '/1927671517284287.87.3\\n', '/192255169334637.968.23\\n', '/19172532990368.327.82\\n', '/1906161108411477.367.39\\n', '/188613611213227.777.08\\n', '/188497273301538.08.28\\n', '/183547195319737.87.74\\n', '/18339053676537.737.79\\n', '/183014963034167.87.65\\n', '/181817296803077.747.59\\n', '/181193369581227.367.33\\n', '/177604455687068.327.57\\n', '/17755492438757.547.49\\n', '/173927523538057.937.45\\n', '/17357772804857.657.7\\n', '/173456550298747.797.96\\n', '/173078572767977.727.02\\n', '/16802784589917.687.88\\n', '/165797398070487.747.37\\n', '/165344376549767.587.73\\n', '/164688932716877.887.42\\n', '/163282378939317.818.78\\n', '/16009370917387.847.6\\n', '/159021206991887.937.99\\n', '/15843370608007.798.04\\n', '/15415820102897.527.77\\n', '/153557100094568.07.99\\n', '/15303457957708.088.14\\n', '/152969200935237.947.51\\n', '/152674217820857.987.86\\n', '/15199033715647.77.91\\n', '/15095673569987.998.33\\n', '/15040959036747.767.3\\n', '/14942036654787.818.33\\n', '/148435106512617.857.86\\n', '/1475113605268.28.14\\n', '/1464401139941887.877.4\\n', '/145401108023337.687.98\\n', '/145217103278707.768.8\\n', '/145172190458757.957.97\\n', '/144638124965637.688.76\\n', '/144624178432497.998.25\\n', '/14308157108837.658.76\\n', '/142895352877257.457.53\\n', '/142580117243887.817.92\\n', '/14202987055157.387.5\\n', '/14191964933448.017.78\\n', '/141613402626587.837.11\\n', '/140841169654677.57.33\\n', '/14065492845917.537.53\\n', '/140337198765067.737.7\\n', '/138522100173087.657.49\\n', '/137244288740878.18.78\\n', '/136166114645117.917.86\\n', '/13493944453797.767.9\\n', '/134196104469587.547.51\\n', '/1337062536368.138.14\\n', '/133262565663577.97.85\\n', '/13260164019697.687.4\\n', '/131467440393287.78.77\\n', '/131420527134147.636.94\\n', '/130038204399597.878.78\\n', '/129230207395337.637.18\\n', '/129183228661707.87.62\\n', '/128205173947467.87.47\\n', '/12810187958407.747.41\\n', '/127554291158667.947.41\\n', '/12601743207197.698.76\\n', '/12485991291308.18.17\\n', '/12456141076737.88.78\\n', '/123676165650797.557.46\\n', '/12352441353917.527.58\\n', '/12332944598727.468.75\\n', '/123141132710697.517.67\\n', '/12290781497767.837.55\\n', '/122785247363987.447.55\\n', '/12249078797807.638.79\\n', '/122187471567887.777.25\\n', '/12120585837447.958.27\\n', '/121070212494107.357.42\\n', '/12093235126637.577.66\\n', '/120217205141127.87.31\\n', '/1200399984087.646.38\\n', '/119186139243717.327.28\\n', '/11904219398597.67.7\\n', '/118951101507267.727.34\\n', '/11733623745917.797.63\\n', '/11666761637737.757.67\\n', '/11662669109037.747.81\\n', '/11626222898537.636.59\\n', '/11493666381947.427.29\\n', '/11470355126607.477.68\\n', '/111910130613377.666.95\\n', '/1117453598018.016.6\\n', '/11162258238897.758.79\\n', '/111131120467927.977.82\\n', '/10500313948337.767.37\\n', '/10481665179267.718.03\\n', '/10475556908257.768.78\\n', '/103813106616667.748.79\\n', '/10342918535527.497.56\\n', '/10227332900027.637.81\\n', '/10186758564897.588.75\\n', '/101540136844947.67.23\\n', '/10152729959717.488.76\\n', '/10144526086047.488.75\\n', '/101443107507117.317.1\\n', '/101357151027907.327.09\\n', '/10022437761717.567.9\\n', '/9997421163597.547.54\\n', '/9992019627367.47.58\\n', '/99699105850467.457.79\\n', '/9953876554647.517.85\\n', '/9948247879957.737.8\\n', '/99337208033297.667.41\\n', '/98409214557407.758.75\\n', '/9553432202797.68.76\\n', '/95476423292437.958.1\\n', '/9540253175247.627.97\\n', '/94121216490637.768.77\\n', '/93415215273037.517.01\\n', '/92416166977007.466.93\\n', '/9211178009087.527.72\\n', '/9205543578397.497.39\\n', '/9202652220157.77.65\\n', '/9190740137467.558.78\\n', '/91679310590907.757.29\\n', '/9141823349838.037.46\\n', '/9082735928677.598.82\\n', '/8890175926447.537.43\\n', '/887715254887.626.6\\n', '/8850669320397.728.03\\n', '/8767740322397.78.83\\n', '/8739625380037.657.75\\n', '/8707320762847.537.29\\n', '/8692313882127.47.48\\n', '/8681085421947.397.6\\n', '/8665846379347.548.75\\n', '/8664520663187.598.81\\n', '/8587233526337.847.39\\n', '/85773138214307.748.04\\n', '/8565972644347.577.82\\n', '/85512131256887.548.79\\n', '/8509848809237.677.88\\n', '/8464416973527.437.95\\n', '/84504627428637.587.32\\n', '/8413534521637.377.45\\n', '/8341630475457.477.76\\n', '/8325027006817.717.27\\n', '/8311173237697.817.75\\n', '/8292153380517.547.76\\n', '/8284374296277.57.15\\n', '/809421900817.917.21\\n', '/79646136752267.347.25\\n', '/79527106676077.437.68\\n', '/7945065868667.47.59\\n', '/7873538679627.527.1\\n', '/78413263947537.527.02\\n', '/78340189316757.356.87\\n', '/7830982096347.548.8\\n', '/7729332835577.458.75\\n', '/7699820795097.67.95\\n', '/7679523029357.628.1\\n', '/7545476631437.477.18\\n', '/7519745568417.757.87\\n', '/7509346079787.347.0\\n', '/7465743271097.527.29\\n', '/74599595207287.46.96\\n', '/7451335020187.397.77\\n', '/7434643384437.577.27\\n', '/73713103426647.467.69\\n', '/73658623607277.698.05\\n', '/7346553513657.587.83\\n', '/73382376135777.668.81\\n', '/73178273088357.556.93\\n', '/7311023063567.57.63\\n', '/7259756085927.317.55\\n', '/7257921708427.517.78\\n', '/7181123367167.387.59\\n', '/7175465404767.397.17\\n', '/71512662278917.917.7\\n', '/7110639923669.398.98\\n', '/7069319326137.417.49\\n', '/7057145016077.377.3\\n', '/6992978006847.377.46\\n', '/6972852363057.327.12\\n', '/69700194695187.767.21\\n', '/6954296992507.597.87\\n', '/69384101694537.356.86\\n', '/6889578386237.457.31\\n', '/6877333869077.417.91\\n', '/68254151963557.516.98\\n', '/6787517390947.548.81\\n', '/6764635101387.397.7\\n', '/6697749903597.487.84\\n', '/6690327095857.517.41\\n', '/6681741624377.448.76\\n', '/6642825209247.786.36\\n', '/6627223603157.516.92\\n', '/6611451050807.498.8\\n', '/6570997392737.487.19\\n', '/6570619851247.487.53\\n', '/6556626033017.347.01\\n', '/6535425834387.397.75\\n', '/65150190306267.596.51\\n', '/65036134000427.346.96\\n', '/6442110410457.547.69\\n', '/6435266401747.337.57\\n', '/6365017072777.668.05\\n', '/6356831493377.377.74\\n', '/6341419961727.428.76\\n', '/625827739497.897.49\\n', '/6252910277357.367.48\\n', '/6211182777067.758.76\\n', '/6210821046677.468.75\\n', '/617376918387.417.42\\n', '/6161748087817.326.7\\n', '/6156221542597.558.76\\n', '/615021011615187.678.75\\n', '/6141839691687.517.52\\n', '/6122429385817.378.75\\n', '/6107838034827.557.16\\n', '/610447608137.47.04\\n', '/60938117961887.337.18\\n', '/6078755876327.517.85\\n', '/6055840451257.798.76\\n', '/604778741167.747.54\\n', '/59709385052807.327.17\\n', '/5960562784677.847.63\\n', '/5914435948087.538.78\\n', '/5895610727197.577.66\\n', '/5872019300617.97.86\\n', '/58719100260447.317.05\\n', '/5870831527287.657.47\\n', '/5845957957128.748.32\\n', '/5803718395157.487.71\\n', '/5778225391537.357.62\\n', '/5760553265307.646.35\\n', '/5756655102537.457.59\\n', '/5746420198797.626.67\\n', '/57209103355517.356.91\\n', '/5710038034787.317.05\\n', '/5702017231457.427.5\\n', '/56920126916607.597.74\\n', '/5677216864887.567.81\\n', '/5670229511177.487.25\\n', '/5652078636607.597.8\\n', '/5602572755057.476.79\\n', '/5600319326947.317.8\\n', '/55755132949627.346.76\\n', '/557198936647.497.63\\n', '/5565324309907.388.75\\n', '/5564911010617.758.8\\n', '/55629240462497.496.37\\n', '/5560122680467.637.35\\n', '/55529141168757.318.76\\n', '/5547723691127.338.76\\n', '/5535813918037.447.57\\n', '/5522429902577.358.76\\n', '/551813966227.366.53\\n', '/551204553147.326.58\\n', '/5460713997697.827.59\\n', '/545646972387.736.06\\n', '/5455724538577.326.52\\n', '/5452322410807.48.75\\n', '/543828433947.428.74\\n', '/5406822020297.327.77\\n', '/5379425658137.637.75\\n', '/536034717427.496.47\\n', '/5341047885427.546.96\\n', '/5322530802387.567.75\\n', '/52530144899307.528.76\\n', '/52344402094207.87.75\\n', '/5199816246417.427.99\\n', '/5177123587127.327.61\\n', '/51555104953567.468.74\\n', '/5139420882527.338.76\\n', '/512428829127.77.62\\n', '/5087053060917.358.04\\n', '/5080320656387.558.75\\n', '/5075085745857.367.22\\n', '/50551278282357.586.93\\n', '/5053727840127.557.8\\n', '/5008240837307.586.81\\n', '/4951745317568.257.93\\n', '/49182142096937.337.15\\n', '/49067237974668.078.02\\n', '/4889028426597.367.13\\n', '/4877833145057.397.11\\n', '/4873562918827.767.63\\n', '/4859720746577.498.75\\n', '/4844437815187.336.89\\n', '/4839731224567.468.75\\n', '/4824910326447.346.75\\n', '/4822726028867.417.38\\n', '/4796331568127.428.75\\n', '/4786919452607.547.5\\n', '/4776824569077.558.8\\n', '/4771893305517.387.15\\n', '/476178593407.797.75\\n', '/4761612996847.477.68\\n', '/4747316179397.67.21\\n', '/4735924794347.566.48\\n', '/4723449768967.317.4\\n', '/4719858108247.367.36\\n', '/4712422377777.527.63\\n', '/4668939060377.496.9\\n', '/465598599857.347.89\\n', '/4598314772037.317.59\\n', '/4591429988347.448.75\\n', '/458185610577.477.53\\n', '/4571752029107.327.53\\n', '/4567926434647.447.52\\n', '/4531210327327.458.74\\n', '/4492675053517.457.23\\n', '/4488230039027.316.99\\n', '/4475412440747.357.65\\n', '/4436616611747.318.78\\n', '/438719127577.557.74\\n', '/4386623743597.57.92\\n', '/4374329804107.358.75\\n', '/4319574630797.467.56\\n', '/43060523857.516.3\\n', '/4285065475517.648.86\\n', '/42688321160737.367.19\\n', '/4240112146297.397.12\\n', '/422696627807.327.88\\n', '/4223917529837.437.86\\n', '/4207823538537.317.8\\n', '/4183730076217.667.42\\n', '/4150288824807.336.68\\n', '/4149016153037.496.9\\n', '/4132726221958.168.76\\n', '/4120624143647.368.77\\n', '/4097646020507.687.49\\n', '/4036927526637.417.73\\n', '/4030030685867.447.66\\n', '/4027666548237.447.05\\n', '/4025111176207.317.68\\n', '/40076113809377.426.91\\n', '/3980528923337.337.42\\n', '/397444756967.787.63\\n', '/3963685930727.516.88\\n', '/3953233674197.477.4\\n', '/39466134240987.637.65\\n', '/3944026323327.758.77\\n', '/3911858656547.597.64\\n', '/3899621344957.537.33\\n', '/3880212620847.367.69\\n', '/3875011794717.647.11\\n', '/3866519240927.487.38\\n', '/3841315212557.327.49\\n', '/3817213701937.47.35\\n', '/3813623341457.667.93\\n', '/3812626015797.328.75\\n', '/3798918568087.377.66\\n', '/3783911977627.327.37\\n', '/3770140959797.697.68\\n', '/3765921122187.438.18\\n', '/376014221247.717.53\\n', '/373722360947.656.73\\n', '/3736210621617.527.84\\n', '/3734531017617.378.75\\n', '/3733125034717.597.87\\n', '/3703722009377.677.45\\n', '/3696526725267.387.91\\n', '/369213532247.357.98\\n', '/3692072842997.317.35\\n', '/3687959970208.738.29\\n', '/3670613152837.318.76\\n', '/3619478437407.527.37\\n', '/3582534959037.438.74\\n', '/35631755487.336.39\\n', '/353121182120237.377.39\\n', '/3530529682397.336.69\\n', '/3504039108107.568.75\\n', '/348208275717.437.35\\n', '/3479218108317.317.06\\n', '/3469438967997.648.04\\n', '/3451013418327.797.68\\n', '/3444821733747.567.52\\n', '/340936104937.327.37\\n', '/3401023900287.448.78\\n', '/3389517352497.58.75\\n', '/3387810789247.337.25\\n', '/338451370337.556.44\\n', '/338447267337.367.21\\n', '/3358310357337.337.17\\n', '/3323610101767.428.79\\n', '/32916117052537.327.22\\n', '/326828109607.558.79\\n', '/325136788857.447.63\\n', '/32435185260777.368.77\\n', '/3224813202237.318.01\\n', '/3216628390867.367.39\\n', '/3212735259197.347.13\\n', '/321079224177.457.72\\n', '/3207820621377.536.9\\n', '/318928425347.318.75\\n', '/3141023030247.338.74\\n', '/3139522826607.427.51\\n', '/313323620777.316.68\\n', '/312485334077.317.21\\n', '/3112416252858.217.8\\n', '/3094332688107.428.76\\n', '/3071215663447.87.77\\n', '/3062114270597.47.18\\n', '/30435111797557.368.46\\n', '/3040435337617.347.53\\n', '/3015223042137.327.32\\n', '/299754179677.697.54\\n', '/2966868619677.437.16\\n', '/2937134989677.46.82\\n', '/2917022615697.67.15\\n', '/291346628627.357.75\\n', '/290554475717.367.55\\n', '/28459238402367.427.58\\n', '/2844127812177.887.64\\n', '/2839322286257.48.74\\n', '/282741220847.346.61\\n', '/28266101931337.337.52\\n']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "#documents = df.values.tolist()\n",
    "fo = open(\"keyword.txt\", \"r\")\n",
    "document = fo.readlines()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split Keywords with all Delimeters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '', 'share', '', 'share', '', 'sharer', 'php', '', '', '', '', '', 'sharersharer', 'php', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'dlpagegaoptout', '', '', '', '', '', '', '', '', '', 'share', 'php', '', '', '', '', '', 'checkshare', '', 'pincreatebutton', '', '', '', '', '', 'cleardnscache', '', 'websiteswebsite-builder', '', '', '', 'css-validatorcheckreferer', '', 'websiteswebsite-builderflashplayer', '', 'shareArticlecheckreferer', '', 'productspanelintro', '', 'flashplayer', '', 'onecom', '', 'Onecom', '', 'productsdesktoppd4wlintro', '', 'intro', '', 'productsdesktopintro', '', 'productsautomationintro', '', 'productsautomationintro', '', 'docsplugins', '', '', '', '', '', 'reader', '', 'home', '', '', '', '', '', 'policy', 'php', '', 'fwlink', '', 'privacy', '', 'sitesignup', '', '', '', 'en', '', '', '', '', '', '', '', 'productsacrobatreadstep2', 'html', '', '', '', 'consumersodr', '', '', '', 'webhosting', '', '', '', '', '', 'pincreatebutton', '', 'intenttweet', '', '', '', '', '', 'communities109881979300958500728', '', '', '', 'bookmark', 'php', '', '', '', '', '', 'Plesk', '', 'muster-disclaimer', 'htm', '', '', '', '', '', 'productscontainersintro', '', 'productsserverintro', '', 'productsserverintro', '', 'gogetflashplayer', '', '', '', 'hostingwebsite-builder', 'aspx', '', 'accountsettings', '', '', '', '', '', 'help17442', '', 'dlpagegaoptout', '', 'phocagallery', '', '', '', '', '', '', '', '', '', 'infodepartmentsjustice-and-consumers_en', '', '', '', '', '', 'share', '', 'share_save', '', 'support', '', '', '', '', '', '', '', '', '', 'windows', '', 'productenwebsitemaker', '', 'producten', '', 'pincreatebutton', '', 'chrome', '', 'policiesprivacyads', '', '', '', '', '', '', '', 'gogetflash', '', '', '', '', '', 'share', 'php', '', '', '', '', '', '', '', '', '', 'policiesprivacy', '', '', '', '', '', 'docs2', '4modmod_userdir', 'html', '', '', '', 'pincreatebutton', '', '', '', '', '', '', '', '', '', 'licensesgpl-2', '0', 'html', '', 'calendarrender', '', '', '', 'calendarrender', '', '', '', '', '', 'privacy_ads', 'html', '', '', '', '', '', 'consumersodr', '', 'webhosting', '', 'aUniversalLogin', '', 'Plesk', '', '', '', 'chromeanswer95647', '', '', '', '', '', 'artikeldatenschutz6590-facebook-like-button-datenschutz-disclaimer', 'html', '', '', '', 'responsive-theme', '', '', '', '', '', 'sharethemesydney', '', '', '', '', '', 'themesydney', '', '', '', '', '', '', '', '', '', 'whois', '', '', '', '', '', 'intlde+policy+1button', 'html', '', 'licensesby2', '0', '', '', '', 'analytics', '', '', '', '', '', '', '', 'intldeanalyticsprivacyoverview', 'html', '', 'themes', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'plugins', '', 'blog', '', 'themes', '', '', '', '', '', '', '', '', '', 'top100', '', 'impressum-generator', 'html', '', 'licensesby-sa3', '0', '', '', '', '', '', 'extendthemes', '', '', '', '', '', 'extendplugins', '', '', '', '', '', '', '', 'it', '', 'migratesharer', 'php', '', '', '', 'analyticstermsde', 'html', '', '', '', 'css-validator', '', 'owa', '', 'index', 'html', '', '', '', 'hc', '', '', '', 'ServiceLogin', '', '', '', 'chrome', '', '', '', '', '', 'aboutprivacy', '', 'choices', '', '', '', 'sharersharer', 'phpjpreader', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'sharer', 'php', '', 'answer23852', '', 'search', '', 'cwsshare', '', 'policy', 'php', '', '', '', 'corehostlist2', '', 'tumblr', '', 'sharelicensesby3', '0', '', 'servicesecurity', '', '', '', 'click', '', 'safari', '', 'muster-datenschutzerklaerung', 'html', '', 'shopify', '', '', '', 'entry', '', 'extendideas', '', '', '', 'home', 'php', '', '', '', '', '', 'supportbinanswer', 'py', '', 'subscribe', 'php', '', 'sharersharer', 'phpplesk', '', '', '', 'maps', '', 'loginshare', 'php', '', '', '', '', '', 'xfn', '', 'themescolormag', '', 'en', '', 'chromeanswer95647check', '', '', '', '', '', '', '', '', '', 'content', '', 'en-uswindows', '', '', '', 'intldepoliciesprivacy', '', '', '', 'custompagecustompagestyle', '', 'intlitpoliciesprivacy', '', '', '', 'gogetflashplayer', '', 'kontakt', '', 'itkbAttivare', '20e', '20disattivare', '20i', '20cookie', '', 'supportforumrequests-and-feedback', '', '', '', 'licensesby-sa2', '0', '', '', '', '', '', 'adswwwdeliveryck', 'php', '', '', '', '', '', '', '', '', '', 'jpproductsacrobatreadstep2', 'html', '', '', '', 'submit', '', '', '', 'save', '', 'artikeldatenschutz6635-datenschutz-rechtliche-risiken-bei-der-nutzung-von-google-analytics-und-googleadsense', 'html', '', '', '', '', '', '', '', 'dlpagegaoptouteskbhabilitar-y-deshabilitar-cookies-que-los-sitios-we', '', '', '', '', '', 'themesspacious', '', 'productsacrobatreadstep', 'html', '', '', '', '', '', '', '', 'share', '', '', '', '', '', '', '', 'go', 'click', '', '', '', 'gmail', '', '', '', 'pluginsasesor-cookies-para-la-ley-en-espana', '', '', '', 'firefoxnew', '', '', '', '', '', '', '', '', '', '', '', 'analyticsanswer6004245', '', 'news', '', '', '', 'faves', '', 'intenttweet', '', 'es-eswindows7how-to-manage-cookies-in-internet-explorer-9', '', '', '', '', '', '', '', '', '', '', '', 'intldepoliciesprivacy', '', '', '', '', '', '', '', 'ModulesPostToPages', '', 'ModulesPostToPages', '', '', '', '', '', '', '', 'share', '', 'kbph5042', '', 'bookmark', 'phpshockwavedownloaddownload', 'cgi', '', 'free-hit-counter', '', 'post', '', 'facebook', '', '', '', 'en-US', '', 'share', '', '', '', '', '', '', '', 'companycontactus', '', '', '', 'chromebinanswer', 'pybookmark', 'phplicensesLICENSE-2', '0', '', 'phocadownload', '', '', '', '', '', 'lyour_new_portfolio', '', '', '', '', '', '', '', 'sharelink', '', 'dereader', '', '', '', 'it-itwindows-vistablock-or-allow-cookies', '', '', '', '', '', '', '', '', '', 'licensesgpl-license', 'php', '', '', '', '', '', '', '', '', '', 'choices', '', 'muster-disclaimer', 'html', '', 'Windows10', '00itcookies', 'html', '', '', '', '', '', 'mac', '', '', '', '', '', '', '', '', '', 'managingopt_out', 'asp', '', '', '', '', '', 'mac', '', '', '', 'businessdashboard', '', 'kbPH5042', '', 'helpDefault', 'aspx', '', '', '', 'analyticslearnprivacy', 'html', '', '_+1confirm', '', '', '', 'legalprivacy-policy', '', '', '', 'licensesby4', '0', '', 'copyleftgpl', 'html', '', '', '', '', '', '', '', 'pincreatebutton', '', 'licensesby-nc-sa3', '0', '', 'submit', '', '', '', '', '', '', '', '', '', 'css-validatorcheckreferer', '', 'appsharefree-web-stats', '', 'submit', '', 'it-itHT201265', '', 'policiestechnologiescookies', '', 'analyticsdevguidescollectionanalyticsjscookie-usagecustomizr', '', '', '', 'customizr', '', '', '', '', '', '', '', 'intlenpoliciesprivacy', '', '', '', 'helpcookies', '', '', '', '', '', 'analyticsdevguidescollectionanalyticsjscookie-usage', '', 'en', '', '', '', '', '', '', '', '', '', '', '', 'index', 'html', '', '', '', 'ukyour-ad-choices', '', 'ideas', '', 'redirectsciaredirect', 'html', '', '', '', '', '', '', '', 'en-USfirefoxnew', '', '', '', 'en-usinternet-explorerproductsiehome', '', 'companyinfo', 'aspx', '', 'intlitpoliciesprivacy', '', '', '', '', '', '', '', 'mail', '', 'dlpagegaoptout', '', 'aboutsmflicense', 'php', '', 'licensesgpl', 'html', '', '', '', '', '', '', '']\n",
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " htm\n",
      " xfn\n",
      " eswindows7how\n",
      " free\n",
      " flashplayer\n",
      " firefoxnew\n",
      " feedback\n",
      " faves\n",
      " facebook\n",
      " extendthemes\n",
      "Cluster 1:\n",
      " html\n",
      " php\n",
      " share\n",
      " en\n",
      " pincreatebutton\n",
      " policy\n",
      " sharersharer\n",
      " submit\n",
      " dlpagegaoptout\n",
      " aspx\n",
      "\n",
      "\n",
      "Prediction\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "with open(\"splitedKeyword.txt\") as f:\n",
    "    content = f.readlines()\n",
    "#list of delimiters in the data file\n",
    "delimiters = ['\\n', ' ', '/', ',', '.', ':', '!', '$', '?', '%', ';', '@']\n",
    "words = content\n",
    "#print(words)\n",
    "for delimiter in delimiters:\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words += word.split(delimiter)\n",
    "    words = new_words\n",
    "print(words)\n",
    "\n",
    "#kmeans algorithm\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "#df = pd.read_csv('splitKeyword.txt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "#documents = df.values.tolist()\n",
    "#fo = open(\"splitedKeyword.txt\", \"r\")\n",
    "#documents = fo.readlines()\n",
    "#print(documents)\n",
    "\n",
    "#documents = [\"This little kitty came to play when I was eating at a restaurant.\",\n",
    " #            \"Merley has the best squooshy kitten belly.\",\n",
    "  #          \"If you open 100 tab in google you get a smiley face.\",\n",
    "   #          \"Best cat photo I've ever taken.\",\n",
    "    #         \"Climbing ninja cat.\",\n",
    "     #        \"Impressed with google map feedback.\",\n",
    "      #       \"Key promoter extension for Google Chrome.\"]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(words)\n",
    "\n",
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "Y = vectorizer.transform([\"chrome browser to open.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"My cat is hungry.\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
